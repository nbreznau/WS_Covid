---
title: "Technical Appendix: Social Inequality, Risk Perceptions and Infection"
output:
  html_document: default
---

#### Nate Breznau
#### Hung H.V. Nguyen
#### Lisa Heukamp
#### *University of Bremen



The following files are necessary to run this code

* *cis2.Rdata* - the data from Breznau (2020) https://osf.io/muhdz/
* *covid-stringency-index.csv* -            https://ourworldindata.org/grapher/covid-stringency-index
* *WID_Data_14082020-111941.xlsx* - https://wid.world/data/
* *swiid8_3.Rda* - Solt (2020) Gini data




Breznau (2020) found that the welfare state probably reduces pandemic risk perceptions, but only for certain countries that failed to take strong government intervention measures. We expect that economic inequality (an outcome of the welfare state, and other things) might be a better indicator of what causes risk perceptions beyond what we would expect given the severity of the local outbreak and government interventions. This is the motivation for the following study.




```{r setup}

rm(list = ls(all = T))

wda <- "C:/GitHub/WS_Covid" #it already has a 'wd' in this datafile so again reset it here
wd <- wda

wdira <- function(x){
  paste(wd,x, sep = "/")
}
# need pacman and ragg packages
# install.packages("pacman")
# devtools::install_github('r-lib/ragg')

pacman::p_load("dplyr","countrycode","car","ggplot2","jtools","sjPlot","sjmisc","sjlabelled","tidyverse","psych","lavaan","kableExtra","ggrepel","stringi","margins","readxl","foreign", "ragg","semTable","htmltools")

```

### Load data

```{r load_prep, message = F, warning = F}
# Breznau 2020
load(file = wdira("cis2.Rdata"))

wd <- wda #it already has a 'wd' in this datafile so again reset it here

wdir <- wdira

rm(wda, wdira)

# pull out se of concern_self by country
cis_a <- select(cis_a, cow, concern_self_se)
finaldf_Ca <- left_join(finaldf_Ca, cis_a, by = "cow")
finaldf_C <- left_join(finaldf_C, cis_a, by = "cow")

# keep only the df of interest
rm(list=ls()[! ls() %in% c("fig1_2","finaldf_C","finaldf_Ca", "wdir", "wd", "deaths_longCa")])

# government response
gov_resp <- read.csv(file = wdir("second_study/covid-stringency-index.csv"), header = T)

# income concentration
top_inc <- read_xlsx(wdir("second_study/WID_Data_14082020-111941.xlsx"))

# Solt Gini
load(wdir("second_study/swiid8_3.Rda"))

# countries to keep (at least 20 cases)
countries <- as.list(finaldf_Ca$cow)

```

### Figure 1. Theoretical Model

```{r fig1, echo = T}
knitr::include_graphics(wdir("second_study/Fig1.png"))
```


### Figure 2
```{r fig1_2, echo = T}
agg_png(file = wdir("second_study/Fig2.png"), width = 1200, height = 1020,  res = 144)
print(fig1_2)
dev.off()
knitr::include_graphics(wdir("second_study/Fig2.png"))
```
### Data cleaning

#### Deaths w 18-day Lead, May 1 - May 20th % increase

Data in deaths_longCa taken from Johns Hopkins https://github.com/CSSEGISandData/COVID-19

Calculate infection severity as 18-day lead deaths increase from April 15th / May 1st to May 31st, and deaths per capita May 31st.


```{r death outcomes}
infect_merge <- as.data.frame(matrix(nrow = 74, ncol = 1))
infect_merge[1:74,1] <- as.numeric(countries)
colnames(infect_merge) <- c("cow")

d1 <- subset(deaths_longCa, date == "2020-05-01", select = c(cow, dead_lead))
d2 <- subset(deaths_longCa, date == "2020-05-31", select = c(cow, dead_lead, dead_1st_date))

infect_merge <- left_join(infect_merge, d1, by = "cow")
infect_merge <- left_join(infect_merge, d2, by = "cow")

colnames(infect_merge) <- c("cow","dead_lead_may1","dead_lead_may31","dead_1st_date")

rm(d1,d2)
```

#### Blavatnik Government Data

A severity scale from researchers at Oxford University. We take the severity of 'lockdown' measures by March 15th to allow for a lag for individuals to become aware of the measures and possibly see their impact. Naumann et al ([2020](https://www.uni-mannheim.de/media/Einrichtungen/gip/Corona_Studie/Schwerpunktbericht_Angstempfinden_Mannheimer_Corona_Studie.pdf)) showed that over time, the 'panic' subsides among the public after strong measures are taken. 

```{r clean_blavatnik, warning = F, message = F}

# get country codes
gov_resp$cow <- countrycode(gov_resp$Entity, "country.name", "cown")

# Create a government average severity scale, since 1st death

dlca <- subset(deaths_longCa, date == "2020-01-30")
dlca <- select(dlca, cow, dead_1st_date)
dlca$dead_1st_date <- as.Date(as.character(dlca$dead_1st_date))

gov_resp <- left_join (gov_resp, dlca, by = "cow")

gov_resp <- subset(gov_resp, !is.na(dead_1st_date))

gov_resp$Date = as.Date(gov_resp$Date, "%d-%b-%y")

colnames(gov_resp) <- c("1","2","Date","gov_resp","cow", "dead_1st_date")

gov_resp <- gov_resp %>%
  group_by(cow) %>%
  mutate(drop = ifelse(Date == "2020-03-15", 0, ifelse(dead_1st_date > Date, 1,  0)),
         gov_resp_a = ifelse(Date == "2020-03-15", gov_resp, NA)) %>%
  ungroup()

gov_resp <- subset(gov_resp, drop == 0)
gov_resp <- select(gov_resp, cow, gov_resp, gov_resp_a, dead_1st_date)
gov_respa <- aggregate(gov_resp, by = list(gov_resp$cow), FUN = mean, na.rm = T)


gov_resp <- select(gov_respa, cow, gov_resp, gov_resp_a, dead_1st_date)
rm(gov_respa)

# impute Grenada, Malta and N Macedonia (using Wikipedia info)
# Grenada, strong lockdown, very few cases. Score = 87
# Malta, moderate measures. Score = 70
# N Macedonia, very strong, near total lockdown. Score = 93

gov_resp[72,1] <- 55
gov_resp[72,3] <- 87

gov_resp[73,1] <- 338
gov_resp[73,3] <- 70

gov_resp[74,1] <- 343
gov_resp[74,3] <- 93

# add in dead_1st_date for the three countries just added (note that this command relies on column '4' being dead_1st_date)

gov_resp[72,4] <- deaths_longCa[deaths_longCa$cow == 55 & deaths_longCa$date == "2020-01-22", 4]
gov_resp[73,4] <- deaths_longCa[deaths_longCa$cow == 338 & deaths_longCa$date == "2020-01-22", 4]
gov_resp[74,4] <- deaths_longCa[deaths_longCa$cow == 343 & deaths_longCa$date == "2020-01-22", 4]

# again impute considering length of time

# very recent, same value
gov_resp[72,2] <- 87

gov_resp[73,2] <- 40
gov_resp[74,2] <- 60

# standardize for ease of interpretation

gov_resp$gov_resp_avg <- as.numeric(scale(gov_resp$gov_resp))
gov_resp$gov_resp = as.numeric(scale(gov_resp$gov_resp_a))

gov_resp <- select(gov_resp, -c(gov_resp_a))

```

#### Income Concentration

As a robustness check we include the top 1% income concentration. We also leave the top 10% concentration in the data here although it has more missing values.

```{r clean_ineq, message = F, warning = F}
top_inc <- top_inc %>%
  mutate(cow = countrycode(Country, "country.name", "cown"))

top_inc1 <- subset(top_inc, top_inc$Percentile == "p99p100")
top_inc2 <- subset(top_inc, top_inc$Percentile == "p90p100")
top_inc1 <- subset(top_inc1, !is.na(top_inc1$cow))
top_inc2 <- subset(top_inc2, !is.na(top_inc2$cow))

# Take the mean from 2010-2019 to account for missing data
top_inc1 <- top_inc1[,c(13:22,23)]
top_inc2 <- top_inc2[,c(3:12,23)]
top_inc1$top1 <- rowMeans(top_inc1[,1:10], na.rm = T)
top_inc2$top10 <- rowMeans(top_inc2[,1:10], na.rm = T)
top_inc1 <- select(top_inc1, cow, top1)
top_inc2 <- select(top_inc2, cow, top10)
# china appears multiple times
top_inc1 <- aggregate(top_inc1, by = list(top_inc1$cow), FUN = mean, na.rm = T)
top_inc2 <- aggregate(top_inc2, by = list(top_inc2$cow), FUN = mean, na.rm = T)
rm(top_inc)

```

#### Solt Gini

The Solt data include multiple measures of the Gini for many countries. We take the average score provided by Solt.

```{r clean_solt, warning = F, message = F}
rm(swiid)
swiid_summary$cow <- countrycode(swiid_summary$country, "country.name", "cown")

#some countries do not have data since 2016, take most recent available year
swiid_summary <- swiid_summary %>%
  mutate(year = ifelse(country == "Algeria" & year == 2011 | country == "Brunei" & year == 1981 | country == "Bosnia and Herzegovina" & year == 2015 | country == "Grenada" & year == 2008 | country == "Guatemala" & year == 2014 | country == "Iceland" & year == 2015 | country == "India" & year == 2012 | country == "Japan" & year == 2015 | country == "Morocco" & year == 2014 | country == "Pakistan" & year == 2015 | country == "Philippines" & year == 2015 | country == "South Africa" & year == 2015 | country == "United Arab Emirates" & year == 2008, 2016, year))

# trim Extremes ZAF BRN
swiid_summary$gini_disp <- ifelse(swiid_summary$gini_disp > 50, 49, swiid_summary$gini_disp)


swiid_summary <- subset(swiid_summary, year >= 2016)
swiid_summary <- select(swiid_summary, cow, gini_disp)
swiid_summary <- aggregate(swiid_summary, by = list(swiid_summary$cow), FUN = mean, na.rm = T)
gini_disp <- select(swiid_summary, cow, gini_disp)

rm(swiid_summary)
```



### Merge Data

```{r merge_clean}

df <- left_join(finaldf_Ca, gov_resp, by = "cow")
df <- left_join(df, gini_disp, by = "cow")
df <- left_join(df, top_inc1, by = "cow")
df <- left_join(df, top_inc2, by = "cow")
df <- left_join(df, infect_merge, by = "cow")

# fix Argentina and Indonesia (last top1 observation was 2004)
df$top1 <- ifelse(df$cow == 160, .168, ifelse(df$cow == 850, .085, df$top1))

```

#### Set up first model

Timing + severity of outbreak should predict risk perceptions.

```{r m1plot}
# adjust risk for severity of outbreak
m1 <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp, data = df)

# predicted values
df$m1p <- predict.lm(m1, df)

# residuals
df$m1r <- df$concern_self - df$m1p 

m1a <- summary(m1)
print(paste0("Adjusted r-square = ", round(m1a[["r.squared"]],3)))
```


#### Infection Rate

```{r rate_calc}

# There was a change in reporting in Spain and the deaths dropped suddenly on May 6th, adjust for this here. 

df$dead_lead_may1 <- ifelse(df$cow == 230, 27000, df$dead_lead_may1)
df <- df %>%
  mutate(rate_2 = ifelse(dead_lead_may31 == 0, 0, (dead_lead_may31 - dead_lead_may1) / (dead_lead_may1)),
         rate_2 = ifelse(rate_2 > 3, 3, rate_2) # trim outliers
  )
```

### Statistics

#### Descriptives

```{r descriptives}


cor <- select(df, concern_self, concern_self_se, days_since_peak, conf_delta, gov_resp, rate_2, gini_disp, top1, socpolicy, gdp)

corm <- cor %>%
  mutate(concern_selfsd = sd(concern_self, na.rm = T),
         concern_self_sesd = sd(concern_self_se, na.rm = T),
         days_since_peaksd = sd(days_since_peak, na.rm = T),
         conf_deltasd = sd(conf_delta, na.rm = T),
         gov_respsd = sd(gov_resp, na.rm = T),
         rate_2sd = sd(rate_2, na.rm = T),
         gini_dispsd = sd(gini_disp, na.rm = T),
         top1sd = sd(top1, na.rm = T),
         socpolicysd = sd(socpolicy, na.rm = T),
         gdpsd = sd(gdp, na.rm = T),concern_self_min = min(concern_self, na.rm = T),
         concern_self_se_min = min(concern_self_se, na.rm = T),
         days_since_peak_min = min(days_since_peak, na.rm = T),
         conf_delta_min = min(conf_delta, na.rm = T),
         gov_resp_min = min(gov_resp, na.rm = T),
         rate_2min = min(rate_2, na.rm = T),
         gini_disp_min = min(gini_disp, na.rm = T),
         top1_min = min(top1, na.rm = T),
         socpolicy_min = min(socpolicy, na.rm = T),
         gdp_min = min(gdp, na.rm = T),
         concern_self_max = max(concern_self, na.rm = T),
         concern_self_se_max = max(concern_self_se, na.rm = T),
         days_since_peak_max = max(days_since_peak, na.rm = T),
         conf_delta_max = max(conf_delta, na.rm = T),
         gov_resp_max = max(gov_resp, na.rm = T),
         rate_2max = max(rate_2, na.rm = T),
         gini_disp_max = max(gini_disp, na.rm = T),
         top1_max = max(top1, na.rm = T),
         socpolicy_max = max(socpolicy, na.rm = T),
         gdp_max = max(gdp, na.rm = T),
         n = ifelse(!is.na(top1), 74, 57),
         concern_self = mean(concern_self, na.rm = T),
         concern_self_se = mean(concern_self_se, na.rm = T),
         days_since_peak = mean(days_since_peak, na.rm = T),
         conf_delta = mean(conf_delta, na.rm = T),
         gov_resp = mean(gov_resp, na.rm = T),
         rate_2 = mean(rate_2, na.rm = T),
         gini_disp = mean(gini_disp, na.rm = T),
         top1 = mean(top1, na.rm = T),
         socpolicy = mean(socpolicy, na.rm = T),
         gdp = mean(gdp, na.rm = T))

cor2 <- round(corm[1,1:10], 2)
cor2[2,] <- round(corm[1,11:20], 2)
cor2[3,] <- round(corm[1,21:30], 2)
cor2[4,] <- round(corm[1,31:40], 2)
cor2[5,1:10] <- 74
cor2[5,8] <- 57

colnames(cor2) <- c("Risk Perception", "SE of Risk Perception by Country", "Days Since Curve Inflection", "New Cases Past Week","Strength of Gov Intervention", "Increase in Infection May1-May20", "Disposable Income Gini", "Top 1% Income Concentration", "Welfare State", "GDP, per capita (k)")

cor2 <- t(cor2)

kable_styling(kable(cor2, col.names = c("Mean", "SD", "Min", "Max", "N")))

```


#### Correlations

```{r corrs}

f1 <- cor(cor, use = "pairwise.complete.obs")


cor1 <- kable(f1, digits = 2, col.names = c("Risk Perception", "SE of Risk Perception by Country", "Days Since Curve Inflection", "New Cases Past Week","Strength of Gov Intervention", "Increase in Infection May1-May20", "Disposable Income Gini", "Top 1% Income Concentration", "Welfare State", "GDP, per capita (k)"))

kable_styling(cor1)
```
#### Additional Fig - Cases per country

```{r plot_case_numbers, echo = T}

ggplot(df, aes(y = concern_self_se, x = cases)) +
  geom_point() +
  xlab("Cases Per Country") +
  ylab("Standard Error of the Mean") +
  theme_classic()

# ggplot(df, aes(x = reorder(iso, concern_self), y = concern_self)) + 
#  geom_bar(stat = "identity") +
#  geom_errorbar(aes(ymin = ymin, ymax = ymax))
```
#### Additional Figs - Residuals

This visualizes the relationship between observed and predicted values of risk perceptions and the regression results used for this prediction.


```{r adjusted_risk, echo = T}



# plot fitted v observed
ggplot(df, aes(y=m1p, x=concern_self)) +
  geom_point() +
  geom_text_repel(aes(label=iso), vjust = 1.5) +
  geom_abline(slope=1) +

  xlab("Observed Risk Perceptions") +
  ylab("Predicted Risk Perceptions") +
  theme_classic()

#   geom_smooth(method=lm, se=FALSE) +

  
```

#### Figure 3

```{r fig3, echo = T}


agg_png(file = wdir("second_study/Fig3.png"), width = 1000, height = 600, res = 144)
ggplot(df, aes(y=m1r, x=gini_disp)) +
  geom_smooth(method=lm, se=T, size = 0.3, color = "gray30") +
  geom_text_repel(aes(label=iso), size = 3, color = "blue4", segment.size = 0.1) +
  xlab("Disposable Income Inequality") +
  ylab("Risk Perceptions (M1 residuals)") +
  labs(title = "Figure 3. Pandemic Risk Perceptions and Economic Inequality", subtitle = "\'Over\' or \'under\' concern explained by income gini") +
  theme_classic() + 
  theme(
  plot.title = element_text(),
  plot.subtitle = element_text(face = "italic"),
  plot.caption = element_text(size = 9, color = "grey30", vjust = -2.5),
  axis.title.x = element_text(vjust = -0.8),
  axis.title.y = element_text(vjust = 2),
  )
invisible(dev.off())
knitr::include_graphics(wdir("second_study/Fig3.png"))
#    
```

#### Additional Fig - 3 Way Plot

```{r plot9, echo = T}
mid <- 34
# trim gini to get better color display
df$gini_color <- ifelse(df$gini_disp<45, df$gini_disp, 45)

ggplot(data=df, aes(x=conf_delta, y=concern_self, color = gini_color)) +
  geom_point() +
  geom_smooth(method=lm, se=FALSE, color = "gray50", linetype = "dashed") +
  geom_text_repel(aes(label = iso), size = 2.8) +
  scale_color_gradient2(midpoint=mid, low="blue", mid="gray55", high="red", space="Lab") +
  labs(x= "New Case Rate, past week", y = "Risk Perceptions", color = "Income Inequality\n(Gini, post\ntax & transfer)") +
      theme(panel.background = element_rect(fill = "white", colour = "grey50"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_text(size = 10))
```

## Main Analyses

### Predicting Risk Perceptions

#### Table 1. M1 through M5

So far this works to convert html to png https://cloudconvert.com/html-to-png, but we should play around with htmltools package to automate this in the code eventually.

```{r reg_gini, echo = T}

#m1x <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp*gov_resp_avg, data = df)

m2 <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + gini_disp, data = df)

# predicted values for sem
df$m2p <- predict.lm(m2, df)

# residuals
df$m2r <- df$concern_self - df$m2p 

m3 <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + socpolicy, data = df)

m4 <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + gdp, data = df)

m5 <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + gini_disp + socpolicy + gdp, data = df)


tab_model(m1, m2, m3, m4, m5, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M1", "M2","M3", "M4","M5"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Disposable Income Inequality", "Welfare State Strength", "GDP Per Capita"), file = wdir("second_study/Tbl1.html"))

tab_model(m1, m2, m3, m4, m5, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M1", "M2","M3", "M4","M5"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Disposable Income Inequality", "Welfare State Strength", "GDP Per Capita"))
```


#### Standardized Coefficients for Table 1

```{r std_reg}
tab_model(m1, m2, m3, m4, m5, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.std = T, dv.labels = c("M1_Z", "M2_Z","M3_Z", "M4_Z","M5_Z"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Disposable Income Inequality", "Welfare State Strength", "GDP Per Capita"))
```

#### Additional Table - The Regression behind Fig 3 (formatted)

```{r resid_reg, echo = T}
m3r <- lm(m1r ~ days_since_peak + conf_delta + gov_resp + gini_disp, data = df)

tab_model(m3r, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.std = T, dv.labels = c("M2_resid"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Intervention Severity", "Disposable Income Inequality"), file = wdir("Tbl2.html"))
```

#### Additional Table - Top 1% instead of Gini

```{r reg_top1, echo = T}
# create dataset with top1 data cases only

dft <- df[(!is.na(df$top1)),]

m1t <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp, data = dft)

m2t <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + top1, data = dft)

m3t <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + socpolicy, data = dft)

m4t <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + gdp, data = dft)

m5t <- lm(concern_self ~ days_since_peak + conf_delta + gov_resp + top1 + socpolicy + gdp, data = dft)

tab_model(m1t, m2t, m3t, m4t, m5t, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M11", "M12","M13", "M14","M15"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Top 1% Income Concentration", "Welfare State Strength", "GDP Per Capita"), file = wdir("second_study/Tbl1_ALT.html"))

tab_model(m1t, m2t, m3t, m4t, m5t, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M11", "M12","M13", "M14","M15"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Top 1% Income Concentration", "Welfare State Strength", "GDP Per Capita"))
```



#### Additional Table - Standardized Results for above

```{r std_reg_top1}
tab_model(m1t, m2t, m3t, m4t, m5t, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.std = T, dv.labels = c("M11_Z", "M12_Z","M13_Z", "M14_Z","M15_Z"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Intervention Severity", "Top 1% Income Concentration", "Welfare State Strength", "GDP Per Capita"))
```



### Predicting Infection Rate, May 1 - May 20

Conf_delta (new cases) measures a type of information the public and media consumes, it is actually a cause of a lower rate of infection, probably because having awareness of a high infection rate leads to behavioral and policy changes. 


#### Table 2. Infection Rate as DV, May 1 - May 21

Predicting deaths using residual risk perceptions.

```{r reg2rate_2}
m21 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp , data = df)

# predicted values
df$m21p <- predict.lm(m21, df)

# residuals
df$m21r <- df$rate_2 - df$m21p

m22 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r, data = df)

m23 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + gini_disp, data = df)

m24 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + socpolicy, data = df)

m25 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + gdp, data = df)

m26 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + gini_disp + socpolicy + gdp, data = df)

tab_model(m21, m22, m23, m24, m25, m26, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M21", "M22","M23", "M24","M25","M26"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Risk Perceptions", "Disposable Income Inequality", "Welfare State Strength", "GDP Per Capita"), file = wdir("second_study/Tbl2.html"))

tab_model(m21, m22, m23, m24, m25, m26, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M21", "M22","M23", "M24","M25","M26"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Risk Perceptions", "Disposable Income Inequality", "Welfare State Strength", "GDP Per Capita"))

```

#### Table 2 Alternate. Using Top 1% instead. 

Predicting deaths using residual risk perceptions.

```{r reg2rate_2_top1}
m31 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp , data = dft)

m32 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r, data = dft)

m33 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + top1, data = dft)

m34 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + socpolicy, data = dft)

m35 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + gdp, data = dft)

m36 <- lm(rate_2 ~ days_since_peak + conf_delta + gov_resp + m2r + top1 + socpolicy + gdp, data = dft)

tab_model(m31, m32, m33, m34, m35, m36, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M31", "M32","M33", "M34","M35","M36"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Risk Perceptions", "Top 1% Income Concentration", "Welfare State Strength", "GDP Per Capita"), file = wdir("second_study/Tbl2_ALT.html"))

tab_model(m31, m32, m33, m34, m35, m36, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.loglik = T, show.aic = T, dv.labels = c("M31", "M32","M33", "M34","M35","M36"), pred.labels = c("Days Since Curve Inflection", "New Case Rate", "Government Intervention", "Risk Perceptions", "Top 1% Income Concentration", "Welfare State Strength", "GDP Per Capita"))

```

#### Effect Size 

Gini coefficient is 0.21 in standardized terms.

```{r tbl2stdz}
tab_model(m23, p.style = "stars", p.threshold = c(0.10, 0.05, 0.01), show.ci = F, rm.terms = c("(Intercept)"), show.std = T)

```



### Mediation Analysis

#### Baseline Model

This is a maximum-likelihood estimated combination of M1 and M22, i.e., a structural equation model.

```{r sem_baseline}
m40 <- '     rate_2 ~ days_since_peak + conf_delta + gov_resp + concern_self
             concern_self ~ days_since_peak + conf_delta + gov_resp 
         '
m40fit <- sem(m40, data = df)
summary(m40fit, fit.measures = T)

Tbl3 <- semTable(m40fit, type = "html", print.results = F)

save_html(Tbl3, wdir("second_study/Tbl3.html"), background = "white", libdir = wdir("second_study/"))

knit_print.html(Tbl3)
#html_print(Tbl3)

```

#### Mediation.

This is a combination of M2 and M23 to parse total, direct and indirect effects.

```{r sem1}
m41 <- '   # direct effect
             rate_2 ~ c*gini_disp + days_since_peak + conf_delta + gov_resp 
           # mediator
             concern_self ~ a*gini_disp + days_since_peak + conf_delta + gov_resp 
             rate_2 ~ b*concern_self 
           # indirect effect (a*b)
             ab := a*b
           # total effect
             total := c + (a*b)
         '
m41fit <- sem(m41, data = df)

Tbl4 <- semTable(m41fit, type = "html", print.results = F)

save_html(Tbl4, wdir("second_study/Tbl4.html"), background = "white", libdir = wdir("second_study/"))

# knit_print.html(Tbl4)

Tbl4p <- html_print(Tbl4)

```

```{r semstdz}
standardizedsolution(m41fit)
```

```{r semstdztotal}
m42_total <- '   # direct effect
             rate_2 ~ gini_disp + days_since_peak + conf_delta + gov_resp 
         '
m42_totalfit <- sem(m42_total, data = df)
summary(m42_totalfit, fit.measures = T)
standardizedsolution(m42_totalfit)
```
```{r fig4_mediation}
knitr::include_graphics(wdir("second_study/Fig4.png"))
```



```{r fig5, echo = T}

# get new residuals from m13

agg_png(file = wdir("second_study/Fig5.png"), width = 1000, height = 600, res = 144)
ggplot(df, aes(y=m21r, x=gini_disp)) +
  geom_smooth(method=lm, formula = y ~ poly(x, 2), se=T, size = 0.3, color = "gray30") +
  geom_text_repel(aes(label=iso), size = 3, color = "blue4", segment.size = 0.1) +
  xlab("Disposable Income Inequality") +
  ylab("Increase in Infections (%),  May 1st-20th") +
  labs(title = "Figure 5. The Spread of COVID-19 and Economic Inequality", subtitle = "Infections not attributable to prior infection rate or government intervention", caption = "\'Increase in Outbreak\' measured as change in COVID-19 deaths per capita, 18-day lead\npredicted residuals from M13 (see Table 2), thus above zero is a greater than expected rate\n after adjusting for severity of outbreak and government measures in April") +
  theme_classic() + 
  theme(
  plot.title = element_text(),
  plot.subtitle = element_text(face = "italic"),
  plot.caption = element_text(size = 9, color = "grey30", vjust = -2.5),
  axis.title.x = element_text(vjust = -0.8),
  axis.title.y = element_text(vjust = 2),
  )
invisible(dev.off())
knitr::include_graphics(wdir("second_study/Fig5.png"))
#    
```




We know that there is a risk of random sampling variation causing disturbance to the results. Therefore we again simulate the variability in the mean risk perceptions by country. 

Get rid of earlier sampling robustness exercise and just do it here for both.

#### Robustness of Coefficients to Sampling Variation. Simulating Plausible Alternative Values for Country-Means

The confidence interval of our regression estimates is based on a sampling distribution across countries, but we have a potentially large source of uncertainty within countries due to the use of an online survey and some very small samples. The online survey problem cannot be solved directly through bootstrapping, but we can asses the robustness of our estimates using the within-country uncertainty. 

There are many countries with small sample sizes (we excluded those with under 20) ranging from 20-50 whereas there are many other countries with over 5,000. This makes for quite an asymmetry in standard error, i.e., the uncertainty associated with each country's mean. Therefore, we bootstrap the estimates by generating random data that follow a normal distribution for each country based on the standard error. Then we run the analysis on each dataset to generate a confidence interval for our estimates that incorporates the within-country standard error of the mean.

```{r robust_sim, message = F, warning = F, include = F}
# The standard error takes into account the sample size, so now we create a simulation standard deviation based on the standard error leading to variation in means across 1000 simulations and a normal distribution.



sim_df <- as.data.frame(matrix(nrow = 1000, ncol = 74))
set.seed(91825)
colnames(sim_df) <- c("sim_2", "sim_20",  "sim_55",  "sim_70",  "sim_90",  "sim_92",  "sim_94", "sim_100", "sim_130", "sim_135", "sim_140", "sim_155", "sim_160", "sim_200", "sim_205", "sim_210", "sim_211", "sim_212", "sim_220", "sim_225", "sim_230", "sim_235", "sim_255", "sim_290", "sim_305", "sim_310", "sim_316", "sim_317", "sim_325", "sim_338", "sim_339", "sim_343", "sim_344", "sim_346", "sim_349", "sim_350", "sim_352", "sim_355", "sim_360", "sim_365", "sim_366", "sim_367", "sim_368", "sim_369", "sim_372", "sim_375", "sim_380", "sim_385", "sim_390", "sim_395", "sim_560", "sim_600", "sim_615", "sim_640", "sim_651", "sim_666", "sim_696", "sim_700", "sim_703", "sim_710", "sim_713", "sim_732", "sim_740", "sim_750", "sim_770", "sim_771", "sim_816", "sim_820", "sim_830", "sim_835", "sim_840", "sim_850", "sim_900", "sim_920")

for (c in countries){
  sim_df[paste0("sim_", c)] <- rnorm(1000, mean = finaldf_Ca[finaldf_Ca$cow == c, "concern_self"], sd = finaldf_Ca[finaldf_Ca$cow == c, "concern_self_se"])
}

sim_df_wide <- as.data.frame(t(sim_df))

sim_df_wide$cow <- finaldf_Ca$cow

finaldf_Ca_sim <- left_join(df, sim_df_wide, by = "cow")


```


```{r robust_reg_a, message = F, warning = F, results='hide', include = F}
for (i in 1:1000){
  name <- paste0("lm",i)
  assign(name, lm(finaldf_Ca_sim[,paste0("V",i)] ~ days_since_peak + conf_delta + gov_resp + gini_disp, data = finaldf_Ca_sim))
}

# coefficients

model.list <- mget(grep("lm[0-9]+$", ls(),value=T))
coefs <- lapply(model.list, function(x)coef(x)[5])


# p-values
pvalues<- lapply(model.list, function(x) summary(x)$coefficients[5,4])
```

Approximate beta coefficient

```{r betasiml, include = F}
tab_model(lm113, show.std = T)

# The average coefficient is 0.026 and this is a standardized effect of 0.20
```

```{r robust_reg_b, message = F, warning = F, results='hide', include = F}
rm(list = ls(pattern = "lm"))
rm(model.list)
results_df <- data.frame(matrix(unlist(coefs), nrow=length(coefs), byrow=T))
results_df[,2] <- data.frame(matrix(unlist(pvalues), nrow=length(pvalues), byrow=T))

colnames(results_df) <- c("coeff","p")
rm(coefs)
rm(pvalues)

```

```{r robust_sim2, message = F, warning = F, include = F}
# Now repeat with a different seed



sim_df <- as.data.frame(matrix(nrow = 1000, ncol = 74))
set.seed(66666)
colnames(sim_df) <- c("sim_2", "sim_20",  "sim_55",  "sim_70",  "sim_90",  "sim_92",  "sim_94", "sim_100", "sim_130", "sim_135", "sim_140", "sim_155", "sim_160", "sim_200", "sim_205", "sim_210", "sim_211", "sim_212", "sim_220", "sim_225", "sim_230", "sim_235", "sim_255", "sim_290", "sim_305", "sim_310", "sim_316", "sim_317", "sim_325", "sim_338", "sim_339", "sim_343", "sim_344", "sim_346", "sim_349", "sim_350", "sim_352", "sim_355", "sim_360", "sim_365", "sim_366", "sim_367", "sim_368", "sim_369", "sim_372", "sim_375", "sim_380", "sim_385", "sim_390", "sim_395", "sim_560", "sim_600", "sim_615", "sim_640", "sim_651", "sim_666", "sim_696", "sim_700", "sim_703", "sim_710", "sim_713", "sim_732", "sim_740", "sim_750", "sim_770", "sim_771", "sim_816", "sim_820", "sim_830", "sim_835", "sim_840", "sim_850", "sim_900", "sim_920")

for (c in countries){
  sim_df[paste0("sim_", c)] <- rnorm(1000, mean = finaldf_Ca[finaldf_Ca$cow == c, "concern_self"], sd = finaldf_Ca[finaldf_Ca$cow == c, "concern_self_se"])
}

sim_df_wide <- as.data.frame(t(sim_df))

sim_df_wide$cow <- finaldf_Ca$cow

finaldf_Ca_sim <- left_join(df, sim_df_wide, by = "cow")


```


```{r robust_reg2, message = F, warning = F, results='hide', include = F}
for (i in 1:1000){
  name <- paste0("lm",i)
  assign(name, lm(finaldf_Ca_sim[,paste0("V",i)] ~ days_since_peak + conf_delta + gov_resp + gini_disp, data = finaldf_Ca_sim))
}

# coefficients

model.list <- mget(grep("lm[0-9]+$", ls(),value=T))
coefs <- lapply(model.list, function(x)coef(x)[5])


# p-values
pvalues<- lapply(model.list, function(x) summary(x)$coefficients[5,4])


rm(list = ls(pattern = "lm"))
rm(model.list)
results_df2 <- data.frame(matrix(unlist(coefs), nrow=length(coefs), byrow=T))
results_df2[,2] <- data.frame(matrix(unlist(pvalues), nrow=length(pvalues), byrow=T))

colnames(results_df2) <- c("coeff","p")
rm(coefs)
rm(pvalues)

```

```{r plot_robust, include = F}
results_df <- bind_rows(results_df, results_df2)
# gen p-value indicator


results_df$group <- ifelse(results_df$p < 0.05, 1, 0)
results_df$group <- as.factor(results_df$group)

ggplot(results_df, aes(x = p, y = coeff, color = group)) +
         geom_point()


```

### Figure 6. Robustness Test of Inequality Effect

Probably just present as a table or report in text.

```{r densityplot, echo = T, include = F}
# mean(results_df$coeff)
# 0.02569374


agg_png(file = wdir("second_study/Fig6.png"), width = 1000, height = 600, res = 144)
ggplot(results_df, aes(x=coeff)) + 
  geom_density() +
  xlab("Effect of Disposable Income Inequality on Risk Perceptions") +
  labs(title = "Figure 3. Robustness of Economic Inequality Effect", subtitle = "Analysis of 2,000 simulated risk perception means \nusing the within-country standard error", caption = "P-values for all 2,000 effects are less than 0.015, with 99.5% of p-values below 0.005.\nCountry case numbers range from 20 to 21,087; mean case numbers 1,452. ") +
  geom_vline(xintercept = 0.02569, linetype="dashed", 
                color = "red", size=1) +
  geom_text(x=0.023, y=10, label="Robust Coefficient \n(average)\n beta = 0.20", color = "red", size = 3) +
    geom_vline(xintercept = 0.03, linetype="dashed", 
                color = "blue", size=1) +
    geom_text(x=0.0326, y=50, label="Observed Coefficient \n(from M2) \nbeta = 0.50", color = "blue", size = 3) +
  theme_classic() +
      theme(
  plot.title = element_text(),
  plot.subtitle = element_text(face = "italic"),
  plot.caption = element_text(size = 9, color = "grey30", vjust = -1.5),
  axis.title.x = element_text(vjust = -0.8),
  axis.title.y = element_blank(),
  )
invisible(dev.off())
knitr::include_graphics(wdir("second_study/Fig6.png"))
```

```{r savepoint}
save(df, file = wdir("second_study/df_gibbs.Rmd"))
```

## References

Breznau, Nate. 2020. “The Welfare State and Risk Perceptions: The Novel Coronavirus Pandemic and Public Concern in 70 Countries.” *European Societies*. [DOI](https://doi.org/10.1080/14616696.2020.1793215)

Solt, Frederick. 2020. "Measuring Income Inequality Across Countries and Over Time: The Standardized World Income Inequality Database." Social Science Quarterly [DOI](https://doi.org/10.1111/ssqu.12795)
